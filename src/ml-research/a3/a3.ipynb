{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "7403dd73",
            "metadata": {},
            "source": [
                "# Assignment 3"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "584502e8",
            "metadata": {},
            "source": [
                "- Go back to Lab assignment 2 and improve the LR result based on the extensions of LR\n",
                "- Classify the weakest link based on the 38 predictors of a movement using a few classification variants(different models or model parameterizations)\n",
                "- Select an accuracy metric\n",
                "- Test and iteratively improve the accuracy of the variants"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ee489676",
            "metadata": {},
            "source": [
                "## Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94d768c8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "\n",
                "sys.path.append(\"../../scripts\")\n",
                "\n",
                "import dagshub\n",
                "import mlflow\n",
                "import ml_utils as MLUtils\n",
                "\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "import statsmodels.api as sm\n",
                "import numpy as np\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "from sklearn.ensemble import GradientBoostingClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "\n",
                "from sklearn.pipeline import make_pipeline\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "from sklearn.utils.class_weight import compute_class_weight\n",
                "from sklearn.ensemble import ExtraTreesClassifier\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ec810111",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "13659116",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup dagshub and MLFlow\n",
                "\n",
                "dagshub.init(repo_owner=\"SamuelFredricBerg\", repo_name=\"4dt907\", mlflow=True)\n",
                "utils = MLUtils.MLUtils(\"Project_Model_A3_V2\")\n",
                "\n",
                "# Configs\n",
                "config = {\n",
                "    \"data_split_seed\": 42,\n",
                "    \"test_size\": 0.2,\n",
                "    \"n_folds\": 10,\n",
                "    \"shuffle\": True,\n",
                "    \"variant\": \"A3-Configurations\",\n",
                "    \n",
                "    \"learning_rate\": 0.1,\n",
                "    \"n_estimators\": 100,\n",
                "    \"max_depth\": None,\n",
                "    \"min_samples_split\": 2,\n",
                "    \"min_samples_leaf\": 5,\n",
                "    \"class_weight\": \"balanced\",\n",
                "\n",
                "    # \"penalty\": \"l2\", \n",
                "    # \"C\": 3.0,             # Strong regularization for stability\n",
                "    # \"solver\": \"lbfgs\",    # Good for multinomial problems\n",
                "    # \"max_iter\": 5000\n",
                "}\n",
                "\n",
                "WeakLink_data_path = \"../../data/AimoScore_WeakLink_big_scores_A3.csv\"\n",
                "Scores_data_path = \"../../data/scores_and_weak_links_A3.csv\"\n",
                "\n",
                "dfw = pd.read_csv(WeakLink_data_path)\n",
                "dfs = pd.read_csv(Scores_data_path)\n",
                "\n",
                "\n",
                "df_final = pd.merge(dfw, dfs, on=\"ID\")\n",
                "\n",
                "\n",
                "weak_link_columns = [\n",
                "    'ForwardHead', 'LeftArmFallForward', 'RightArmFallForward',\n",
                "    'LeftShoulderElevation', 'RightShoulderElevation', 'ExcessiveForwardLean',\n",
                "    'LeftAsymmetricalWeightShift', 'RightAsymmetricalWeightShift',\n",
                "    'LeftKneeMovesInward', 'RightKneeMovesInward', 'LeftKneeMovesOutward',\n",
                "    'RightKneeMovesOutward', 'LeftHeelRises', 'RightHeelRises'\n",
                "]\n",
                "\n",
                "df_final['WeakestLink'] = df_final[weak_link_columns].idxmax(axis=1)\n",
                "\n",
                "\n",
                "kf = KFold(\n",
                "    n_splits=config[\"n_folds\"],\n",
                "    shuffle=config[\"shuffle\"],\n",
                "    random_state=config[\"data_split_seed\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "46666c22",
            "metadata": {},
            "source": [
                "# Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6d90bde4",
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocessing(df):\n",
                "    df_cleaned = df\n",
                "    return df_cleaned"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3ccbcadd",
            "metadata": {},
            "source": [
                "# Plots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1f0ce26",
            "metadata": {},
            "outputs": [],
            "source": [
                "def confuse_matrix(X, y, model):\n",
                "    # 1. Train on a single split to see real predictions\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "    model.fit(X_train, y_train)\n",
                "    y_pred = model.predict(X_test)\n",
                "\n",
                "    all_labels = weak_link_columns \n",
                "\n",
                "    fig, ax = plt.subplots(figsize=(12, 10)) \n",
                "    ConfusionMatrixDisplay.from_predictions(\n",
                "        y_test, \n",
                "        y_pred, \n",
                "        ax=ax, \n",
                "        display_labels=all_labels, # Force these labels on the axes\n",
                "        labels=all_labels,         # Ensure it looks for all 14\n",
                "        cmap='Blues', \n",
                "        xticks_rotation=90\n",
                "    )\n",
                "    plt.title(\"Weakest Link Prediction: 14-Class Matrix\")\n",
                "    plt.tight_layout() # Prevents label cutoff\n",
                "    plt.savefig(\"matrix.png\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1ae6fc6f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def crossval_boxplots(f1_raw, acc_raw, prec_raw, rec_raw):\n",
                "    # 1. Create a dictionary of the raw arrays\n",
                "    raw_data = {\n",
                "        'F1 Score': f1_raw,\n",
                "        'Accuracy': acc_raw,\n",
                "        'Precision': prec_raw,\n",
                "        'Recall': rec_raw\n",
                "    }\n",
                "    \n",
                "    # 2. Convert to 'Long Format' (This is why your plot was likely clamped)\n",
                "    df_plot = pd.DataFrame(raw_data).melt(var_name='Metric', value_name='Score')\n",
                "    \n",
                "    # 3. Plotting\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    \n",
                "    # Setting the style to whitegrid helps readability\n",
                "    sns.set_style(\"whitegrid\")\n",
                "    \n",
                "    # Use 'Metric' for x and 'Score' for y\n",
                "    ax = sns.boxplot(x='Metric', y='Score', data=df_plot, palette=\"Set3\", width=0.4)\n",
                "    sns.swarmplot(x='Metric', y='Score', data=df_plot, color=\".25\", size=7)\n",
                "\n",
                "    # 4. Smart Scaling: Instead of 0 to 1, let's zoom in on the data \n",
                "    # but keep a little padding so we can see the whiskers\n",
                "    ymin = df_plot['Score'].min() - 0.05\n",
                "    ymax = df_plot['Score'].max() + 0.05\n",
                "    plt.ylim(max(0, ymin), min(1, ymax)) # Ensure we don't go out of 0-1 range\n",
                "    \n",
                "    plt.title(f'Model Stability: {config[\"variant\"]}\\n(Zoomed in to show variance)')\n",
                "    plt.ylabel('Score Value')\n",
                "    \n",
                "    plt.savefig(\"boxplot.png\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39347d09",
            "metadata": {},
            "source": [
                "## Main Code"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "949ec79f",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "with mlflow.start_run(run_name=\"A3-Training-RFC\") as run:\n",
                "    mlflow.log_params(config)\n",
                "\n",
                "\n",
                "    y = df_final['WeakestLink']\n",
                "    cheating_cols = weak_link_columns + [\n",
                "    'WeakestLink', 'ID', 'Date', 'SCORE', 'AimoScore', \n",
                "    'EstimatedScore', 'label score'\n",
                "    ]\n",
                "\n",
                "    X = df_final.drop(columns=[c for c in cheating_cols if c in df_final.columns], errors='ignore')\n",
                "\n",
                "    X = X.select_dtypes(include=[np.number])\n",
                "\n",
                "    \n",
                "\n",
                "    model = RandomForestClassifier(\n",
                "        n_estimators=config[\"n_estimators\"],\n",
                "        max_depth=config[\"max_depth\"],\n",
                "        min_samples_split=config[\"min_samples_split\"],\n",
                "        random_state=config[\"data_split_seed\"],\n",
                "        class_weight=config[\"class_weight\"],\n",
                "        min_samples_leaf=config[\"min_samples_leaf\"],\n",
                "    )\n",
                "    #model = GradientBoostingClassifier(\n",
                "    #    n_estimators=config[\"n_estimators\"],\n",
                "    #    learning_rate=config[\"learning_rate\"], \n",
                "    #    max_depth=config[\"max_depth\"],\n",
                "    #    random_state=config[\"data_split_seed\"],\n",
                "    #    min_samples_split=config[\"min_samples_split\"],\n",
                "    #    min_samples_leaf=config[\"min_samples_leaf\"]\n",
                "    #)\n",
                "    # model = make_pipeline(\n",
                "    # StandardScaler(), \n",
                "    # LogisticRegression(\n",
                "    #     penalty=config[\"penalty\"],\n",
                "    #     C=config[\"C\"],\n",
                "    #     solver=config[\"solver\"],\n",
                "    #     max_iter=config[\"max_iter\"],\n",
                "    #     multi_class='multinomial',\n",
                "    #     class_weight='balanced',\n",
                "    #     random_state=config[\"data_split_seed\"]\n",
                "    #     )\n",
                "    # )\n",
                "\n",
                "\n",
                "    # model = ExtraTreesClassifier(\n",
                "    #     n_estimators=config[\"n_estimators\"],\n",
                "    #     max_depth=config[\"max_depth\"],\n",
                "    #     min_samples_leaf=config[\"min_samples_leaf\"],\n",
                "    #     random_state=config[\"data_split_seed\"],\n",
                "    #     class_weight=config[\"class_weight\"],\n",
                "    #     n_jobs=-1\n",
                "    # )\n",
                "\n",
                "    print(\"Model Done\")\n",
                "\n",
                "    model.fit(X, y)\n",
                "\n",
                "    print(\"Fitting done\")\n",
                "\n",
                "    confuse_matrix(X, y, model)\n",
                "\n",
                "\n",
                "    f1_scores = cross_val_score(model, X, y, cv=kf, scoring='f1_weighted')\n",
                "    accuracy = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
                "    precision = cross_val_score(model, X, y, cv=kf, scoring='precision_weighted')\n",
                "    recall = cross_val_score(model, X, y, cv=kf, scoring='recall_weighted')\n",
                "\n",
                "    results = {\n",
                "        \"F1_Mean\": f1_scores.mean(),\n",
                "        \"F1_Std\": f1_scores.std(),\n",
                "        \"Accuracy_Mean\": accuracy.mean(),\n",
                "        \"Precision_Mean\": precision.mean(),\n",
                "        \"Recall_Mean\": recall.mean()\n",
                "    }\n",
                "    print(results)\n",
                "\n",
                "    crossval_boxplots(f1_scores,accuracy,precision,recall)\n",
                "\n",
                "    mlflow.log_metrics(results)\n",
                "\n",
                "    mlflow.log_artifact(\"boxplot.png\")\n",
                "    mlflow.log_artifact(\"matrix.png\")\n",
                "\n",
                "    if utils.auto_check_challenger(run.info.run_id, metric_name=\"F1_Mean\"):\n",
                "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=\"Project_Model_A3_V2\")\n",
                "        latest_v = utils.client.get_latest_versions(\"Project_Model_A3_V2\")[0].version\n",
                "        utils.client.set_registered_model_alias(\"Project_Model_A3_V2\", \"dev\", latest_v)\n",
                "        print(\"New model beat current @dev uploading to DagsHub\")\n",
                "    else:\n",
                "        print(\"Did not beat current @dev, model not uploaded to Dagshub\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
