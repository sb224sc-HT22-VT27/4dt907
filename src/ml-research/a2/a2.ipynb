{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7403dd73",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee489676",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d768c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "import scripts.ML_utils as MLUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec810111",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13659116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dagshub and MLFlow\n",
    "dagshub.init(repo_owner=\"SamuelFredricBerg\", repo_name=\"4dt907\", mlflow=True)\n",
    "utils = MLUtils(\"Project_Model\")\n",
    "\n",
    "\n",
    "# Add all configs used in the training (EXAMPLE BELOW)\n",
    "config = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": 7,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_set\": \"v2_processed\",\n",
    "    \"data_split_seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39347d09",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ec79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"ADD_RUN_NAME_HERE\") as run:\n",
    "    mlflow.log_params(config)\n",
    "\n",
    "\n",
    "    # TRAINING CODE GOES HERE\n",
    "    # model = train_model()\n",
    "\n",
    "    # Logging results\n",
    "    # Create a dictionary for all results (EXAMPLE BELOW)\n",
    "    results = {\n",
    "        \"accuracy\": 0.942,\n",
    "        \"f1_score\": 0.915,\n",
    "        \"precision\": 0.920,\n",
    "        \"recall\": 0.910\n",
    "    }\n",
    "    mlflow.log_metrics(results)\n",
    "\n",
    "    # Logging visuals\n",
    "    # Example how to below\n",
    "    # plt.savefig(\"feature_importance.png\")\n",
    "    # mlflow.log_artifact(\"feature_importance.png\")\n",
    "\n",
    "    if utils.auto_check_challenger(run.info.run_id, metric_name=\"accuracy\"):\n",
    "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=\"Project_Model\")\n",
    "\n",
    "        latest_v = utils.client.get_latest_versions(\"Project_Model\")[0].version\n",
    "        utils.client.set_registered_model_alias(\"Project_Model\", \"dev\", latest_v)\n",
    "        print(\"New model beat current @dev uploading to DagsHub\")\n",
    "    else:\n",
    "        print(\"Did not beat current @dev, model not uploaded to Dagshub\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
